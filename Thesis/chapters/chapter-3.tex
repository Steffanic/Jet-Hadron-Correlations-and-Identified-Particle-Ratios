\chapter{Methods} \label{ch:methods}

Analyses in large experiments and particle colliders are often several steps removed from the direct measuring tools of the experiment. The raw data are measured and recorded by the detector, then the signals are processed and analyzed by a combination of hardware and software to reconstruct the data that represents a physical object, such as a particle, or a jet. Physical observables are then calculated from the reconstructed data and used to draw conclusions. The following sections describe the reconstruction process and the observables used in this analysis.

\section{Data}

The data used in this analysis were measured in 2017 and 2018 during Run 2 of the LHC. The data were measured from proton-proton collisions at a center-of-mass energy of $\sqrt{s} = 2.01$ TeV and lead-lead collisions at $\sqrt{s_{NN}} = 5.02$ TeV. The data were collected by the ALICE detector using a minimum bias trigger for the proton-proton events, and a centrality trigger for the lead-lead events, in addition to the minimum bias trigger. This analysis studies 0-10\% centrality collisions, referred to as central events throughout, and 30-50\% centrality collisions, referred to as semicentral collisions throughout. We used XXM events in the proton-proton sample, XXM events in the central lead-lead sample, and XXM events in the semicentral lead-lead sample.

\section{Reconstruction}

The raw detector data go through several steps to reconstruct the data that represent physical objects. The raw signals are first aggregated into local clusters within each detector, and referred to as hits. The hits are then used as input to reconstruct tracks, the trails of hits left behind by a charged particle, and vertices, the collision locations. From the reconstructed tracks, we can reconstruct jets and calculate jet observables. Some of these steps are carried out in hardware circuits and others are done long after the data are measured, in software. There are many nuances in the reconstruction process beyond the scope of this thesis. The interested reader can see the official ALICE reconstruction documentation~\cite{ALICEreco}.

\subsection{Vertex Reconstruction}

The primary vertices, the locations of the collision for each event, are randomly distributed about the center of the detector along the x, y, and z directions. Each collision system will have a different beam profile resulting in a different distribution of primary vertices. The innermost layers of the ITS are used to measure the distributions of particle positions near the primary vertex in both the transverse and longitudinal directions. Once tracks have been reconstructed, we can provide a better estimate of the primary vertex location by projecting the tracks back to point of convergence. This improves the primary vertex resolution by a factor of two~\cite{trackVertexReconstruction}.

\subsection{Track Reconstruction}

Tracking refers to the process of taking all of the hits, clusters of signals left by particles, measured in various detectors during a single event and reconstructing the path that each particle took through the detector volume. This can be done globally, considering all hits and simultaneously reconstructing all particle trajectories. Alternatively, tracking can be done locally, building particle trajectories one step at a time. The ALICE detector uses a local tracking method that iteratively applies a Kalman Filter to reconstruct particle trajectories. A detailed discussion of Kalman Filtering can be found in~\cite{Kalman}.
The first step in track reconstruction is cluster finding, where the raw detector signals are grouped together into clusters, which are assumed to represent a particle hit in the active detector volume. Some corrections are applied the to the cluster position arising from the details of the detectors, like TPC space-charge corrections, and overlapping clusters. The next step is track finding, where the clusters are grouped together into track candidates. The algorithm starts by finding ”seed tracks” which can be followed and combined with clusters to produce the final track. These seed tracks can be found in different ways. One can apply a vertex constraint and generate seed tracks using clusters close to the primary vertex that project back to it, and then add clusters in the outer TPC that lie in a small window projected from the primary vertex along the other cluster locations. Alternatively, one can start in the middle of the TPC and find clusters that are nearby to each other until a stopping condition is met. These methods are complementary as some tracks require a primary vertex constraint, while other tracks will suffer from the use of such a constraint. Once the seed tracks are found, they are followed in multiple passes to the innermost and outermost layers of the TPC. Along the way, clusters are considered if they are within 4$\sigma$ of the current track, and the nearest cluster is accepted as the most probable cluster for that track. Tracks are then further extended into the ITS using the Kalman Filtering approach that is slightly modified to account for the increased occupancy in the ITS, as well as the dead zone between the ITS and the TPC. The tracks are finally propagated out to the outermost detectors, including the TRD and TOF. In addition to position information, momentum information and several other observables related to particle identification are also calculated and assigned to the track.